import { createLogger } from '@aztec/foundation/log';
import { Semaphore, SerialQueue } from '@aztec/foundation/queue';
import { MsgpackChannel, NativeLMDBStore } from '@aztec/native';
import { AsyncLocalStorage } from 'async_hooks';
import { mkdir, rm } from 'fs/promises';
import { LMDBArray } from './array.js';
import { LMDBMap } from './map.js';
import { Database, LMDBMessageType } from './message.js';
import { LMDBMultiMap } from './multi_map.js';
import { ReadTransaction } from './read_transaction.js';
import { LMDBSet } from './set.js';
import { LMDBSingleValue } from './singleton.js';
import { WriteTransaction } from './write_transaction.js';
export { execInReadTx, execInWriteTx } from './tx-helpers.js';
export class AztecLMDBStoreV2 {
    dataDir;
    log;
    cleanup;
    open;
    channel;
    writerCtx;
    writerQueue;
    availableCursors;
    constructor(dataDir, mapSize, maxReaders, log, cleanup){
        this.dataDir = dataDir;
        this.log = log;
        this.cleanup = cleanup;
        this.open = false;
        this.writerCtx = new AsyncLocalStorage();
        this.writerQueue = new SerialQueue();
        this.log.info(`Starting data store with maxReaders ${maxReaders}`);
        this.channel = new MsgpackChannel(new NativeLMDBStore(dataDir, mapSize, maxReaders));
        // leave one reader to always be available for regular, atomic, reads
        this.availableCursors = new Semaphore(maxReaders - 1);
    }
    get dataDirectory() {
        return this.dataDir;
    }
    async start() {
        this.writerQueue.start();
        await this.channel.sendMessage(LMDBMessageType.OPEN_DATABASE, {
            db: Database.DATA,
            uniqueKeys: true
        });
        await this.channel.sendMessage(LMDBMessageType.OPEN_DATABASE, {
            db: Database.INDEX,
            uniqueKeys: false
        });
        this.open = true;
    }
    static async new(dataDir, dbMapSizeKb = 10 * 1024 * 1024, maxReaders = 16, cleanup, bindings) {
        const log = createLogger('kv-store:lmdb-v2', bindings);
        const db = new AztecLMDBStoreV2(dataDir, dbMapSizeKb, maxReaders, log, cleanup);
        await db.start();
        return db;
    }
    async backupTo(dstPath, compact = true) {
        await mkdir(dstPath, {
            recursive: true
        });
        await this.channel.sendMessage(LMDBMessageType.COPY_STORE, {
            dstPath,
            compact
        });
    }
    getReadTx() {
        if (!this.open) {
            throw new Error('Store is closed');
        }
        return new ReadTransaction(this);
    }
    getCurrentWriteTx() {
        if (!this.open) {
            throw new Error('Store is closed');
        }
        const currentWrite = this.writerCtx.getStore();
        return currentWrite;
    }
    openMap(name) {
        return new LMDBMap(this, name);
    }
    openMultiMap(name) {
        return new LMDBMultiMap(this, name);
    }
    openSingleton(name) {
        return new LMDBSingleValue(this, name);
    }
    openArray(name) {
        return new LMDBArray(this, name);
    }
    openSet(name) {
        return new LMDBSet(this, name);
    }
    openCounter(_name) {
        throw new Error('Not implemented');
    }
    async transactionAsync(callback) {
        if (!this.open) {
            throw new Error('Store is closed');
        }
        // transactionAsync might be called recursively
        // send any writes to the parent tx, but don't close it
        // if the callback throws then the parent tx will rollback automatically
        const currentTx = this.getCurrentWriteTx();
        if (currentTx) {
            return await callback(currentTx);
        }
        return this.writerQueue.put(async ()=>{
            const tx = new WriteTransaction(this);
            try {
                const res = await this.writerCtx.run(tx, callback, tx);
                await tx.commit();
                return res;
            } catch (err) {
                this.log.error(`Failed to commit transaction`, err);
                throw err;
            } finally{
                tx.close();
            }
        });
    }
    clear() {
        return Promise.resolve();
    }
    async delete() {
        await this.close();
        await rm(this.dataDir, {
            recursive: true,
            force: true,
            maxRetries: 3
        });
        this.log.verbose(`Deleted database files at ${this.dataDir}`);
        await this.cleanup?.();
    }
    async close() {
        if (!this.open) {
            // already closed
            return;
        }
        this.open = false;
        await this.writerQueue.cancel();
        await this.channel.sendMessage(LMDBMessageType.CLOSE, undefined);
    }
    async sendMessage(msgType, body) {
        if (!this.open) {
            throw new Error('Store is closed');
        }
        if (msgType === LMDBMessageType.START_CURSOR) {
            await this.availableCursors.acquire();
        }
        let response = undefined;
        try {
            ({ response } = await this.channel.sendMessage(msgType, body));
            return response;
        } finally{
            if (msgType === LMDBMessageType.START_CURSOR && response === undefined || msgType === LMDBMessageType.CLOSE_CURSOR || // it's possible for a START_CURSOR command to not return a cursor (e.g. db is empty)
            msgType === LMDBMessageType.START_CURSOR && typeof response.cursor !== 'number') {
                this.availableCursors.release();
            }
        }
    }
    async estimateSize() {
        const resp = await this.sendMessage(LMDBMessageType.STATS, undefined);
        return {
            mappingSize: Number(resp.dbMapSizeBytes),
            physicalFileSize: Number(resp.dbPhysicalFileSizeBytes),
            actualSize: resp.stats.reduce((s, db)=>Number(db.totalUsedSize) + s, 0),
            numItems: resp.stats.reduce((s, db)=>Number(db.numDataItems) + s, 0)
        };
    }
}
