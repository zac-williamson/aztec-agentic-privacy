import { BlobAccumulator, FinalBlobBatchingChallenges } from '@aztec/blob-lib/types';
import { ARCHIVE_HEIGHT, BLOBS_PER_CHECKPOINT, FIELDS_PER_BLOB, OUT_HASH_TREE_HEIGHT } from '@aztec/constants';
import { BLS12Point } from '@aztec/foundation/curves/bls12';
import { Fr } from '@aztec/foundation/curves/bn254';
import { bufferSchemaFor } from '@aztec/foundation/schemas';
import { BufferReader, serializeToBuffer } from '@aztec/foundation/serialize';
import { bufferToHex, hexToBuffer } from '@aztec/foundation/string';
import { ProofData } from '../proofs/proof_data.js';
import { AppendOnlyTreeSnapshot } from '../trees/append_only_tree_snapshot.js';
import { BlockHeader } from '../tx/block_header.js';
import { BlockRollupPublicInputs } from './block_rollup_public_inputs.js';
export class CheckpointRootRollupHints {
    previousBlockHeader;
    previousArchiveSiblingPath;
    previousOutHash;
    newOutHashSiblingPath;
    startBlobAccumulator;
    finalBlobChallenges;
    blobFields;
    blobCommitments;
    blobsHash;
    constructor(/**
     * The header of the previous block before this checkpoint.
     */ previousBlockHeader, /**
     * Hint for checking the hash of previous_block_header is the last leaf of the previous archive.
     */ previousArchiveSiblingPath, /**
     * The out hash tree snapshot immediately before this checkpoint.
     */ previousOutHash, /**
     * Hint for inserting the new out hash into the out hash tree.
     */ newOutHashSiblingPath, /**
     * The current blob accumulation state across the epoch.
     */ startBlobAccumulator, /**
     * Finalized challenges z and gamma for performing blob batching. Shared value across the epoch.
     */ finalBlobChallenges, /**
     * Flat list of all tx effects which will be added to the blob.
     * Below line gives error 'Type instantiation is excessively deep and possibly infinite. ts(2589)'
     * Tuple<Fr, FIELDS_PER_BLOB * BLOBS_PER_CHECKPOINT>
     */ blobFields, /**
     * KZG commitments representing the blob (precomputed in ts, injected to use inside circuit).
     */ blobCommitments, /**
     * The hash of eth blob hashes for this block
     * See yarn-project/foundation/src/blob/index.ts or body.ts for calculation
     */ blobsHash){
        this.previousBlockHeader = previousBlockHeader;
        this.previousArchiveSiblingPath = previousArchiveSiblingPath;
        this.previousOutHash = previousOutHash;
        this.newOutHashSiblingPath = newOutHashSiblingPath;
        this.startBlobAccumulator = startBlobAccumulator;
        this.finalBlobChallenges = finalBlobChallenges;
        this.blobFields = blobFields;
        this.blobCommitments = blobCommitments;
        this.blobsHash = blobsHash;
    }
    static from(fields) {
        return new CheckpointRootRollupHints(...CheckpointRootRollupHints.getFields(fields));
    }
    static getFields(fields) {
        return [
            fields.previousBlockHeader,
            fields.previousArchiveSiblingPath,
            fields.previousOutHash,
            fields.newOutHashSiblingPath,
            fields.startBlobAccumulator,
            fields.finalBlobChallenges,
            fields.blobFields,
            fields.blobCommitments,
            fields.blobsHash
        ];
    }
    toBuffer() {
        return serializeToBuffer(...CheckpointRootRollupHints.getFields(this));
    }
    static fromBuffer(buffer) {
        const reader = BufferReader.asReader(buffer);
        return new CheckpointRootRollupHints(BlockHeader.fromBuffer(reader), reader.readArray(ARCHIVE_HEIGHT, Fr), reader.readObject(AppendOnlyTreeSnapshot), reader.readArray(OUT_HASH_TREE_HEIGHT, Fr), reader.readObject(BlobAccumulator), reader.readObject(FinalBlobBatchingChallenges), // Below line gives error 'Type instantiation is excessively deep and possibly infinite. ts(2589)'
        // reader.readArray(FIELDS_PER_BLOB, Fr),
        Array.from({
            length: FIELDS_PER_BLOB * BLOBS_PER_CHECKPOINT
        }, ()=>Fr.fromBuffer(reader)), reader.readArray(BLOBS_PER_CHECKPOINT, BLS12Point), Fr.fromBuffer(reader));
    }
    toString() {
        return bufferToHex(this.toBuffer());
    }
    static fromString(str) {
        return CheckpointRootRollupHints.fromBuffer(hexToBuffer(str));
    }
    toJSON() {
        return this.toBuffer();
    }
    static get schema() {
        return bufferSchemaFor(CheckpointRootRollupHints);
    }
}
export class CheckpointRootRollupPrivateInputs {
    previousRollups;
    hints;
    constructor(previousRollups, hints){
        this.previousRollups = previousRollups;
        this.hints = hints;
    }
    static from(fields) {
        return new CheckpointRootRollupPrivateInputs(...CheckpointRootRollupPrivateInputs.getFields(fields));
    }
    static getFields(fields) {
        return [
            fields.previousRollups,
            fields.hints
        ];
    }
    toBuffer() {
        return serializeToBuffer(...CheckpointRootRollupPrivateInputs.getFields(this));
    }
    static fromBuffer(buffer) {
        const reader = BufferReader.asReader(buffer);
        return new CheckpointRootRollupPrivateInputs([
            ProofData.fromBuffer(reader, BlockRollupPublicInputs),
            ProofData.fromBuffer(reader, BlockRollupPublicInputs)
        ], CheckpointRootRollupHints.fromBuffer(reader));
    }
    toString() {
        return bufferToHex(this.toBuffer());
    }
    static fromString(str) {
        return CheckpointRootRollupPrivateInputs.fromBuffer(hexToBuffer(str));
    }
    toJSON() {
        return this.toBuffer();
    }
    static get schema() {
        return bufferSchemaFor(CheckpointRootRollupPrivateInputs);
    }
}
export class CheckpointRootSingleBlockRollupPrivateInputs {
    previousRollup;
    hints;
    constructor(previousRollup, hints){
        this.previousRollup = previousRollup;
        this.hints = hints;
    }
    static from(fields) {
        return new CheckpointRootSingleBlockRollupPrivateInputs(...CheckpointRootSingleBlockRollupPrivateInputs.getFields(fields));
    }
    static getFields(fields) {
        return [
            fields.previousRollup,
            fields.hints
        ];
    }
    toBuffer() {
        return serializeToBuffer(...CheckpointRootSingleBlockRollupPrivateInputs.getFields(this));
    }
    static fromBuffer(buffer) {
        const reader = BufferReader.asReader(buffer);
        return new CheckpointRootSingleBlockRollupPrivateInputs(ProofData.fromBuffer(reader, BlockRollupPublicInputs), CheckpointRootRollupHints.fromBuffer(reader));
    }
    toString() {
        return bufferToHex(this.toBuffer());
    }
    static fromString(str) {
        return CheckpointRootSingleBlockRollupPrivateInputs.fromBuffer(hexToBuffer(str));
    }
    toJSON() {
        return this.toBuffer();
    }
    static get schema() {
        return bufferSchemaFor(CheckpointRootSingleBlockRollupPrivateInputs);
    }
}
// Checkpoint padding circuit does not have any private inputs.
export class CheckpointPaddingRollupPrivateInputs {
    constructor(){}
    toBuffer() {
        return Buffer.alloc(0);
    }
    static fromBuffer(_buffer) {
        return new CheckpointPaddingRollupPrivateInputs();
    }
    toString() {
        return '0x';
    }
    static fromString(_str) {
        return new CheckpointPaddingRollupPrivateInputs();
    }
    toJSON() {
        return this.toBuffer();
    }
    static get schema() {
        return bufferSchemaFor(CheckpointPaddingRollupPrivateInputs);
    }
}
