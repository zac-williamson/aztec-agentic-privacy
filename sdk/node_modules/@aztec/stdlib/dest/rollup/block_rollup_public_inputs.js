import { SpongeBlob } from '@aztec/blob-lib/types';
import { Fr } from '@aztec/foundation/curves/bn254';
import { bufferSchemaFor } from '@aztec/foundation/schemas';
import { BufferReader, bigintToUInt64BE, serializeToBuffer } from '@aztec/foundation/serialize';
import { bufferToHex, hexToBuffer } from '@aztec/foundation/string';
import { AppendOnlyTreeSnapshot } from '../trees/append_only_tree_snapshot.js';
import { StateReference } from '../tx/state_reference.js';
import { CheckpointConstantData } from './checkpoint_constant_data.js';
/**
 * Output of the block root and block merge rollup circuits.
 */ export class BlockRollupPublicInputs {
    constants;
    previousArchive;
    newArchive;
    startState;
    endState;
    startSpongeBlob;
    endSpongeBlob;
    timestamp;
    blockHeadersHash;
    inHash;
    outHash;
    accumulatedFees;
    accumulatedManaUsed;
    constructor(/**
     * Constants for the entire checkpoint.
     */ constants, /**
     * Archive tree immediately before this block range.
     */ previousArchive, /**
     * Archive tree after applying this block range.
     */ newArchive, /**
     * State reference immediately before this block range.
     */ startState, /**
     * State reference after applying this block range.
     */ endState, /**
     * Sponge state to absorb blob inputs at the start of this block range.
     */ startSpongeBlob, /**
     * Sponge state to absorb blob inputs at the end of this block range.
     */ endSpongeBlob, /**
     * Timestamp of the blocks in this block range.
     */ timestamp, /**
     * Hash of the headers of all blocks in this block range. It will be combined with the `blockHeadersHash` from
     * other blocks in the same checkpoint to form an unbalanced tree. The root of that tree becomes the final hash
     * stored in the checkpoint header, enabling validation of the blocks included in a checkpoint given their headers.
     */ blockHeadersHash, /**
     * SHA256 hash of l1 to l2 messages.
     */ inHash, /**
     * SHA256 hash of L2 to L1 messages created in this block range.
     */ outHash, /**
     * The summed transaction fees of all the txs in this block range.
     */ accumulatedFees, /**
     * The summed mana used of all the txs in this block range.
     */ accumulatedManaUsed){
        this.constants = constants;
        this.previousArchive = previousArchive;
        this.newArchive = newArchive;
        this.startState = startState;
        this.endState = endState;
        this.startSpongeBlob = startSpongeBlob;
        this.endSpongeBlob = endSpongeBlob;
        this.timestamp = timestamp;
        this.blockHeadersHash = blockHeadersHash;
        this.inHash = inHash;
        this.outHash = outHash;
        this.accumulatedFees = accumulatedFees;
        this.accumulatedManaUsed = accumulatedManaUsed;
    }
    static fromBuffer(buffer) {
        const reader = BufferReader.asReader(buffer);
        return new BlockRollupPublicInputs(reader.readObject(CheckpointConstantData), reader.readObject(AppendOnlyTreeSnapshot), reader.readObject(AppendOnlyTreeSnapshot), reader.readObject(StateReference), reader.readObject(StateReference), reader.readObject(SpongeBlob), reader.readObject(SpongeBlob), reader.readUInt64(), Fr.fromBuffer(reader), Fr.fromBuffer(reader), Fr.fromBuffer(reader), Fr.fromBuffer(reader), Fr.fromBuffer(reader));
    }
    toBuffer() {
        return serializeToBuffer(this.constants, this.previousArchive, this.newArchive, this.startState, this.endState, this.startSpongeBlob, this.endSpongeBlob, bigintToUInt64BE(this.timestamp), this.blockHeadersHash, this.inHash, this.outHash, this.accumulatedFees, this.accumulatedManaUsed);
    }
    toString() {
        return bufferToHex(this.toBuffer());
    }
    static fromString(str) {
        return BlockRollupPublicInputs.fromBuffer(hexToBuffer(str));
    }
    toJSON() {
        return this.toBuffer();
    }
    static get schema() {
        return bufferSchemaFor(BlockRollupPublicInputs);
    }
}
