import { ARCHIVE_HEIGHT, L1_TO_L2_MSG_SUBTREE_ROOT_SIBLING_PATH_LENGTH } from '@aztec/constants';
import { Fr } from '@aztec/foundation/curves/bn254';
import { bufferSchemaFor } from '@aztec/foundation/schemas';
import { BufferReader, bigintToUInt64BE, serializeToBuffer } from '@aztec/foundation/serialize';
import { ParityPublicInputs } from '../parity/parity_public_inputs.js';
import { ProofData } from '../proofs/proof_data.js';
import { AppendOnlyTreeSnapshot } from '../trees/append_only_tree_snapshot.js';
import { StateReference } from '../tx/state_reference.js';
import { CheckpointConstantData } from './checkpoint_constant_data.js';
import { TxRollupPublicInputs } from './tx_rollup_public_inputs.js';
export class BlockRootFirstRollupPrivateInputs {
    l1ToL2Roots;
    previousRollups;
    previousL1ToL2;
    newL1ToL2MessageSubtreeRootSiblingPath;
    newArchiveSiblingPath;
    constructor(/**
     * The original and converted roots of the L1 to L2 messages subtrees.
     */ l1ToL2Roots, /**
     * The previous rollup proof data from base or merge rollup circuits.
     */ previousRollups, /**
     * The l1 to l2 message tree snapshot immediately before this block.
     */ previousL1ToL2, /**
     * Hint for inserting the new l1 to l2 message subtree root into `previousL1ToL2`.
     */ newL1ToL2MessageSubtreeRootSiblingPath, /**
     * Hint for inserting the new block hash to the last archive.
     */ newArchiveSiblingPath){
        this.l1ToL2Roots = l1ToL2Roots;
        this.previousRollups = previousRollups;
        this.previousL1ToL2 = previousL1ToL2;
        this.newL1ToL2MessageSubtreeRootSiblingPath = newL1ToL2MessageSubtreeRootSiblingPath;
        this.newArchiveSiblingPath = newArchiveSiblingPath;
    }
    static from(fields) {
        return new BlockRootFirstRollupPrivateInputs(...BlockRootFirstRollupPrivateInputs.getFields(fields));
    }
    static getFields(fields) {
        return [
            fields.l1ToL2Roots,
            fields.previousRollups,
            fields.previousL1ToL2,
            fields.newL1ToL2MessageSubtreeRootSiblingPath,
            fields.newArchiveSiblingPath
        ];
    }
    toBuffer() {
        return serializeToBuffer(...BlockRootFirstRollupPrivateInputs.getFields(this));
    }
    static fromBuffer(buffer) {
        const reader = BufferReader.asReader(buffer);
        return new BlockRootFirstRollupPrivateInputs(ProofData.fromBuffer(reader, ParityPublicInputs), [
            ProofData.fromBuffer(reader, TxRollupPublicInputs),
            ProofData.fromBuffer(reader, TxRollupPublicInputs)
        ], AppendOnlyTreeSnapshot.fromBuffer(reader), reader.readArray(L1_TO_L2_MSG_SUBTREE_ROOT_SIBLING_PATH_LENGTH, Fr), reader.readArray(ARCHIVE_HEIGHT, Fr));
    }
    toJSON() {
        return this.toBuffer();
    }
    static get schema() {
        return bufferSchemaFor(BlockRootFirstRollupPrivateInputs);
    }
}
export class BlockRootSingleTxFirstRollupPrivateInputs {
    l1ToL2Roots;
    previousRollup;
    previousL1ToL2;
    newL1ToL2MessageSubtreeRootSiblingPath;
    newArchiveSiblingPath;
    constructor(/**
     * The original and converted roots of the L1 to L2 messages subtrees.
     */ l1ToL2Roots, /**
     * The previous rollup proof data from base or merge rollup circuits.
     */ previousRollup, /**
     * The l1 to l2 message tree snapshot immediately before this block.
     */ previousL1ToL2, /**
     * Hint for inserting the new l1 to l2 message subtree root.
     */ newL1ToL2MessageSubtreeRootSiblingPath, /**
     * Hint for inserting the new block hash to the last archive.
     */ newArchiveSiblingPath){
        this.l1ToL2Roots = l1ToL2Roots;
        this.previousRollup = previousRollup;
        this.previousL1ToL2 = previousL1ToL2;
        this.newL1ToL2MessageSubtreeRootSiblingPath = newL1ToL2MessageSubtreeRootSiblingPath;
        this.newArchiveSiblingPath = newArchiveSiblingPath;
    }
    static from(fields) {
        return new BlockRootSingleTxFirstRollupPrivateInputs(...BlockRootSingleTxFirstRollupPrivateInputs.getFields(fields));
    }
    static getFields(fields) {
        return [
            fields.l1ToL2Roots,
            fields.previousRollup,
            fields.previousL1ToL2,
            fields.newL1ToL2MessageSubtreeRootSiblingPath,
            fields.newArchiveSiblingPath
        ];
    }
    toBuffer() {
        return serializeToBuffer(...BlockRootSingleTxFirstRollupPrivateInputs.getFields(this));
    }
    static fromBuffer(buffer) {
        const reader = BufferReader.asReader(buffer);
        return new BlockRootSingleTxFirstRollupPrivateInputs(ProofData.fromBuffer(reader, ParityPublicInputs), ProofData.fromBuffer(reader, TxRollupPublicInputs), AppendOnlyTreeSnapshot.fromBuffer(reader), reader.readArray(L1_TO_L2_MSG_SUBTREE_ROOT_SIBLING_PATH_LENGTH, Fr), reader.readArray(ARCHIVE_HEIGHT, Fr));
    }
    toJSON() {
        return this.toBuffer();
    }
    static get schema() {
        return bufferSchemaFor(BlockRootSingleTxFirstRollupPrivateInputs);
    }
}
export class BlockRootEmptyTxFirstRollupPrivateInputs {
    l1ToL2Roots;
    previousArchive;
    previousState;
    constants;
    timestamp;
    newL1ToL2MessageSubtreeRootSiblingPath;
    newArchiveSiblingPath;
    constructor(/**
     * The original and converted roots of the L1 to L2 messages subtrees.
     */ l1ToL2Roots, /**
     * The archive after applying the previous block.
     */ previousArchive, /**
     * The state reference of the previous block.
     */ previousState, /**
     * The constants of the checkpoint.
     */ constants, /**
     * The timestamp of this block.
     */ timestamp, /**
     * Hint for inserting the new l1 to l2 message subtree root.
     */ newL1ToL2MessageSubtreeRootSiblingPath, /**
     * Hint for inserting the new block hash to the last archive.
     */ newArchiveSiblingPath){
        this.l1ToL2Roots = l1ToL2Roots;
        this.previousArchive = previousArchive;
        this.previousState = previousState;
        this.constants = constants;
        this.timestamp = timestamp;
        this.newL1ToL2MessageSubtreeRootSiblingPath = newL1ToL2MessageSubtreeRootSiblingPath;
        this.newArchiveSiblingPath = newArchiveSiblingPath;
    }
    static from(fields) {
        return new BlockRootEmptyTxFirstRollupPrivateInputs(...BlockRootEmptyTxFirstRollupPrivateInputs.getFields(fields));
    }
    static getFields(fields) {
        return [
            fields.l1ToL2Roots,
            fields.previousArchive,
            fields.previousState,
            fields.constants,
            fields.timestamp,
            fields.newL1ToL2MessageSubtreeRootSiblingPath,
            fields.newArchiveSiblingPath
        ];
    }
    toBuffer() {
        return serializeToBuffer([
            this.l1ToL2Roots,
            this.previousArchive,
            this.previousState,
            this.constants,
            bigintToUInt64BE(this.timestamp),
            this.newL1ToL2MessageSubtreeRootSiblingPath,
            this.newArchiveSiblingPath
        ]);
    }
    static fromBuffer(buffer) {
        const reader = BufferReader.asReader(buffer);
        return new BlockRootEmptyTxFirstRollupPrivateInputs(ProofData.fromBuffer(reader, ParityPublicInputs), AppendOnlyTreeSnapshot.fromBuffer(reader), StateReference.fromBuffer(reader), CheckpointConstantData.fromBuffer(reader), reader.readUInt64(), reader.readArray(L1_TO_L2_MSG_SUBTREE_ROOT_SIBLING_PATH_LENGTH, Fr), reader.readArray(ARCHIVE_HEIGHT, Fr));
    }
    toJSON() {
        return this.toBuffer();
    }
    static get schema() {
        return bufferSchemaFor(BlockRootEmptyTxFirstRollupPrivateInputs);
    }
}
export class BlockRootRollupPrivateInputs {
    previousRollups;
    newArchiveSiblingPath;
    constructor(/**
     * The previous rollup proof data from base or merge rollup circuits.
     */ previousRollups, /**
     * Hint for inserting the new block hash to the last archive.
     */ newArchiveSiblingPath){
        this.previousRollups = previousRollups;
        this.newArchiveSiblingPath = newArchiveSiblingPath;
    }
    static from(fields) {
        return new BlockRootRollupPrivateInputs(...BlockRootRollupPrivateInputs.getFields(fields));
    }
    static getFields(fields) {
        return [
            fields.previousRollups,
            fields.newArchiveSiblingPath
        ];
    }
    toBuffer() {
        return serializeToBuffer(...BlockRootRollupPrivateInputs.getFields(this));
    }
    static fromBuffer(buffer) {
        const reader = BufferReader.asReader(buffer);
        return new BlockRootRollupPrivateInputs([
            ProofData.fromBuffer(reader, TxRollupPublicInputs),
            ProofData.fromBuffer(reader, TxRollupPublicInputs)
        ], reader.readArray(ARCHIVE_HEIGHT, Fr));
    }
    toJSON() {
        return this.toBuffer();
    }
    static get schema() {
        return bufferSchemaFor(BlockRootRollupPrivateInputs);
    }
}
export class BlockRootSingleTxRollupPrivateInputs {
    previousRollup;
    newArchiveSiblingPath;
    constructor(/**
     * The previous rollup proof data from base or merge rollup circuits.
     */ previousRollup, /**
     * Hint for inserting the new block hash to the last archive.
     */ newArchiveSiblingPath){
        this.previousRollup = previousRollup;
        this.newArchiveSiblingPath = newArchiveSiblingPath;
    }
    static from(fields) {
        return new BlockRootSingleTxRollupPrivateInputs(...BlockRootSingleTxRollupPrivateInputs.getFields(fields));
    }
    static getFields(fields) {
        return [
            fields.previousRollup,
            fields.newArchiveSiblingPath
        ];
    }
    toBuffer() {
        return serializeToBuffer(...BlockRootSingleTxRollupPrivateInputs.getFields(this));
    }
    static fromBuffer(buffer) {
        const reader = BufferReader.asReader(buffer);
        return new BlockRootSingleTxRollupPrivateInputs(ProofData.fromBuffer(reader, TxRollupPublicInputs), reader.readArray(ARCHIVE_HEIGHT, Fr));
    }
    toJSON() {
        return this.toBuffer();
    }
    static get schema() {
        return bufferSchemaFor(BlockRootSingleTxRollupPrivateInputs);
    }
}
